# -*- coding: utf-8 -*-
"""Face Recognition with LBPH.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1NHa8x51JYWqBXeoZShAqlU-mnUncYmHG
"""

from google.colab import drive
drive.mount('/content/drive')

"""IMPORT LIBRARIES"""

import PIL
from PIL import Image
import cv2
import numpy as np
import zipfile
import os
from sklearn.metrics import accuracy_score, confusion_matrix
import seaborn as sns
import dlib
from google.colab.patches import cv2_imshow

"""**READ IN DATASET**"""

path = '/content/drive/MyDrive/Face Recognition/yalefaces.zip'

zip_object = zipfile.ZipFile(file=path, mode='r')

zip_object.extractall('./')

zip_object.close()

"""**PRE-PROCESS IMAGE**"""

zip_object

print(os.listdir("/content/drive/MyDrive/Face Recognition/yalefaces/train"))

def get_image_data():
    paths = [os.path.join("/content/drive/MyDrive/Face Recognition/yalefaces/train", f) for f in os.listdir("/content/drive/MyDrive/Face Recognition/yalefaces/train")]
    faces = []
    ids = []
    for path in paths:
        image = Image.open(path).convert('L')
        image_np = np.array(image, 'uint8')
        id = int(os.path.split(path)[1].split('.')[0].replace('subject', ''))
        ids.append(id)
        faces.append(image_np)
    return np.array(ids), faces

ids, faces = get_image_data()

ids

faces

"""**TRAINING THE LBPH CLASSIFIER**"""

lpbh_classifier = cv2.face.LBPHFaceRecognizer_create()

lpbh_classifier.train(faces, ids)

lpbh_classifier.write('/content/drive/MyDrive/Face Recognition/lbph_classifier.yml')

"""**RECOGNIZEING FACES**"""

lbph_face_classifier = cv2.face.LBPHFaceRecognizer_create()

lbph_face_classifier.read(r"/content/drive/MyDrive/Face Recognition/lbph_classifier.yml")

"""**TESTING**"""

test_image = "/content/drive/MyDrive/Face Recognition/yalefaces/test/subject09.sad.gif"

image = Image.open(test_image).convert('L')
image_np = np.array(image, 'uint8')

prediction = lbph_face_classifier.predict(image_np)

expected_output = int(os.path.split(test_image)[1].split('.')[0].replace('subject',''))

cv2.putText(image_np, 'Pred:'+ str(prediction[0]), (10,20), cv2.FONT_HERSHEY_COMPLEX_SMALL, 1, (0,255,0))
cv2.putText(image_np, 'Exp:'+ str(expected_output), (10,50), cv2.FONT_HERSHEY_COMPLEX_SMALL, 1, (0,255,0))
cv2_imshow(image_np)
cv2.waitKey(0)
cv2.destroyAllWindows()

"""**EVALUATE THE FACE CLASSIFIER**"""

paths = [os.path.join("/content/drive/MyDrive/Face Recognition/yalefaces/test", f) for f in os.listdir("/content/drive/MyDrive/Face Recognition/yalefaces/test")]
predictions = []
expected_outputs = []

for path in paths:
    image = Image.open(path).convert('L')
    image_np = np.array(image, 'uint8')

    prediction, _ = lbph_face_classifier.predict(image_np)
    expected_output = int(os.path.split(path)[1].split('.')[0].replace('subject', ''))

    predictions.append(prediction)
    expected_outputs.append(expected_output)

predictions = np.array(predictions)
expected_outputs = np.array(expected_outputs)

accuracy_score(expected_outputs, predictions)

cm = confusion_matrix(expected_outputs, predictions)

cm

sns.heatmap(cm, annot=True);

"""**DETECT FACIAL POINTS**"""

face_detector = dlib.get_frontal_face_detector()
points_detector = dlib.shape_predictor("/content/drive/MyDrive/Face Recognition/Weights/shape_predictor_68_face_landmarks.dat")

image = cv2.imread("/content/drive/MyDrive/Face Recognition/Images/people2.jpg")
face_detection = face_detector(image, 1)
for face in face_detection:
  points = points_detector(image, face)
  for point in points.parts():
    cv2.circle(image, (point.x, point.y), 2, (0,255,0), 1)

  #print(points.parts())
  #print(len(points.parts()))

  l, t, r, b = face.left(), face.top(), face.right(), face.bottom()
  cv2.rectangle(image, (l, t), (r, b), (0,255,255), 2)
cv2_imshow(image)

"""**DETECTING FACIAL DESCRIPTORS**"""

# Resnet: https://arxiv.org/abs/1512.03385
face_detector = dlib.get_frontal_face_detector()
points_detector = dlib.shape_predictor('/content/drive/MyDrive/Face Recognition/Weights/shape_predictor_68_face_landmarks.dat')
face_descriptor_extractor = dlib.face_recognition_model_v1('/content/drive/MyDrive/Face Recognition/Weights/dlib_face_recognition_resnet_model_v1.dat')

index = {}
idx = 0
face_descriptors = None

paths = [os.path.join('/content/yalefaces/train', f) for f in os.listdir('/content/yalefaces/train')]
for path in paths:
  #print(path)
  image = Image.open(path).convert('RGB')
  image_np = np.array(image, 'uint8')
  face_detection = face_detector(image_np, 1)
  for face in face_detection:
    l, t, r, b = face.left(), face.top(), face.right(), face.bottom()
    cv2.rectangle(image_np, (l, t), (r, b), (0, 0, 255), 2)

    points = points_detector(image_np, face)
    for point in points.parts():
      cv2.circle(image_np, (point.x, point.y), 2, (0, 255, 0), 1)

    face_descriptor = face_descriptor_extractor.compute_face_descriptor(image_np, points)
    #print(type(face_descriptor))
    #print(len(face_descriptor))
    #print(face_descriptor)
    face_descriptor = [f for f in face_descriptor]
    #print(face_descriptor)
    face_descriptor = np.asarray(face_descriptor, dtype=np.float64)
    #print(face_descriptor)
    #print(face_descriptor.shape)
    face_descriptor = face_descriptor[np.newaxis, :]
    #print(face_descriptor.shape)
    #print(face_descriptor)

    if face_descriptors is None:
      face_descriptors = face_descriptor
    else:
      face_descriptors = np.concatenate((face_descriptors, face_descriptor), axis = 0)

    index[idx] = path
    idx += 1
  cv2_imshow(image_np)

face_descriptors.shape

face_descriptors

len(index)

index

"""CALCULATE THE DISTANCE BETWEEN FACES"""

face_descriptors[131]

# https://numpy.org/doc/stable/reference/generated/numpy.linalg.norm.html#numpy.linalg.norm
np.linalg.norm(face_descriptors[131] - face_descriptors[131])

np.linalg.norm(face_descriptors[131] - face_descriptors[130])

np.linalg.norm(face_descriptors[131] - face_descriptors[130])

np.linalg.norm(face_descriptors[131] - face_descriptors[128])

np.linalg.norm(face_descriptors[131] - face_descriptors[128])

np.linalg.norm(face_descriptors[0] - face_descriptors, axis = 1)

np.argmin(np.linalg.norm(face_descriptors[0] - face_descriptors[1:], axis = 1))

np.linalg.norm(face_descriptors[0] - face_descriptors[1:], axis = 1)[91]

"""**DETECTING FACES WITH DLIB**"""

threshold = 0.5
predictions = []
expected_outputs = []

paths = [os.path.join('/content/yalefaces/test', f) for f in os.listdir('/content/yalefaces/test')]
for path in paths:
  image = Image.open(path).convert('RGB')
  image_np = np.array(image, 'uint8')
  face_detection = face_detector(image_np, 1)
  for face in face_detection:
    points = points_detector(image_np, face)
    face_descriptor = face_descriptor_extractor.compute_face_descriptor(image_np, points)
    face_descriptor = [f for f in face_descriptor]
    face_descriptor = np.asarray(face_descriptor, dtype=np.float64)
    face_descriptor = face_descriptor[np.newaxis, :]

    distances = np.linalg.norm(face_descriptor - face_descriptors, axis = 1)
    min_index = np.argmin(distances)
    min_distance = distances[min_index]
    if min_distance <= threshold:
      name_pred = int(os.path.split(index[min_index])[1].split('.')[0].replace('subject', ''))
    else:
      name_pred = 'Not identified'

    name_real = int(os.path.split(path)[1].split('.')[0].replace('subject', ''))

    predictions.append(name_pred)
    expected_outputs.append(name_real)

    cv2.putText(image_np, 'Pred: ' + str(name_pred), (10, 30), cv2.FONT_HERSHEY_COMPLEX_SMALL, 1, (0,255,0))
    cv2.putText(image_np, 'Exp : ' + str(name_real), (10, 50), cv2.FONT_HERSHEY_COMPLEX_SMALL, 1, (0,255,0))


  cv2_imshow(image_np)

predictions = np.array(predictions)
expected_outputs = np.array(expected_outputs)

predictions

expected_outputs

accuracy_score(expected_outputs, predictions)

cm = confusion_matrix(expected_outputs, predictions)

cm

sns.heatmap(cm, annot=True)