{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15f71df3-c88f-4568-a250-56bc23b379e8",
   "metadata": {},
   "source": [
    "**IMPORT NECESSARY LIBRARIES**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7796511b-7442-45fd-8f98-1f8c19e8602c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c881cb8-d02f-48a7-abb5-3779d01d3f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read image\n",
    "img = cv2.imread(\"people1.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7e4c173-9e15-445b-929c-41124771c7e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1280, 1920, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b95ad240-6cae-4df1-b642-460d7120e113",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View image\n",
    "cv2.imshow('window pane', img) \n",
    "cv2.waitKey(0) \n",
    "cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11b41ec2-bcd9-4c3e-8a90-c8affee36f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resize image\n",
    "img = cv2.resize(img, (800,600))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "95b85fc5-9306-45ce-af56-182c7fa1b48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('window pane', img) \n",
    "cv2.waitKey(0) \n",
    "cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8bf5f516-df7f-4b24-8f2a-51206fade753",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(600, 800, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "12366c5f-2b76-421e-91bd-669496f95f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert he image to grayscale\n",
    "gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "61472247-190d-435a-825a-661707887444",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('window pane', gray_img) \n",
    "cv2.waitKey(0) \n",
    "cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d525da17-5ffa-4751-ad7f-246716959ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect Face\n",
    "face_detector = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "detections = face_detector.detectMultiScale(gray_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cc24a1b2-4853-4ebe-b3a0-a8689847c516",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[390, 323,  56,  56],\n",
       "       [387, 233,  73,  73],\n",
       "       [ 92, 239,  66,  66],\n",
       "       [115, 124,  53,  53],\n",
       "       [677,  72,  68,  68],\n",
       "       [475, 123,  59,  59]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detections"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b36adf1c-449c-44fd-9870-b15acff8ba70",
   "metadata": {},
   "source": [
    "*6 rows means that six faces were detected of which the first two cells per row is the x and y coordinates*\n",
    "*and the last two cells represents the width and height*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f830ec84-b4b8-4000-b205-db4b06c1af45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(detections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cdb9ab13-188f-41ea-a46c-e65f25411966",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a bounding box\n",
    "for (x_coor, y_coor, weight, height) in detections:\n",
    "    #print(x_coor, y_coor, weight, height)\n",
    "    cv2.rectangle(img, (x_coor, y_coor), (x_coor+weight, y_coor+height), (0,255,0), thickness=2)\n",
    "    \n",
    "cv2.imshow('window pane', img)\n",
    "cv2.waitKey(0) \n",
    "cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb2c6538-fa01-48b4-a8b0-5444aedf823d",
   "metadata": {},
   "source": [
    "*There is a false face identification, so we have to take it out*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35abc752-db65-4bb1-a5c0-7c333d041c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def front_face_detection(image_path):\n",
    "    # Read image\n",
    "    img = cv2.imread(image_path)\n",
    "    # Convert the image to grayscale\n",
    "    gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    # Create the face detector instance\n",
    "    face_detector = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "    # Detect the faces\n",
    "    face_detections = face_detector.detectMultiScale(gray_img, scaleFactor=1.3, minSize=(30,30))\n",
    "    # Create the bounding box on the original image\n",
    "    for (x_coor, y_coor, weight, height) in face_detections:\n",
    "        cv2.rectangle(img, (x_coor, y_coor), (x_coor+weight, y_coor+height), (0,255,0), thickness=2)\n",
    "    # Save the image\n",
    "    cv2.imwrite('face_detection_result.png', img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9bb7dbf-56ec-417f-86e3-3ee7fc24c2bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"people1.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78565634-bd3f-49fa-aad4-c3332116fb78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "result = front_face_detection(image_path=file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b74d88e1-cb33-43f7-9652-dac6d4c20944",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eyes_detection(image_path):\n",
    "    # Read image\n",
    "    img = cv2.imread(image_path)\n",
    "    # Convert the image to grayscale\n",
    "    gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    # Create the face detector instance\n",
    "    eye_detector = cv2.CascadeClassifier('haarcascade_eye.xml')\n",
    "    # Detect the eyes\n",
    "    eye_detections = eye_detector.detectMultiScale(gray_img, scaleFactor=1.1, minNeighbors=10, maxSize=(70,70))\n",
    "    # Create the bounding box on the original image\n",
    "    for (x_coor, y_coor, weight, height) in eye_detections:\n",
    "        cv2.rectangle(img, (x_coor, y_coor), (x_coor+weight, y_coor+height), (0,0,250), thickness=2)\n",
    "    # Save the image\n",
    "    cv2.imwrite('eye_detection_result.png', img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f42e2431-123a-4543-929f-1377c47ba99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "result = eyes_detection(image_path=file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50f24aea-a44d-48c6-8710-ae6988edb45d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def face_eyes_detection(image_path):\n",
    "    # Read image\n",
    "    img = cv2.imread(image_path)\n",
    "    # Convert the image to grayscale\n",
    "    gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    # Create the face detector instance\n",
    "    face_detector = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "    # Detect the faces\n",
    "    face_detections = face_detector.detectMultiScale(gray_img, scaleFactor=1.3, minSize=(30,30))\n",
    "    # Create the bounding box on the original image\n",
    "    for (x_coor, y_coor, weight, height) in face_detections:\n",
    "        cv2.rectangle(img, (x_coor, y_coor), (x_coor+weight, y_coor+height), (0,255,0), thickness=2)\n",
    "    # Create the face detector instance\n",
    "    eye_detector = cv2.CascadeClassifier('haarcascade_eye.xml')\n",
    "    # Detect the eyes\n",
    "    eye_detections = eye_detector.detectMultiScale(gray_img, scaleFactor=1.1, minNeighbors=10, maxSize=(70,70))\n",
    "    # Create the bounding box on the original image\n",
    "    for (x_coor, y_coor, weight, height) in eye_detections:\n",
    "        cv2.rectangle(img, (x_coor, y_coor), (x_coor+weight, y_coor+height), (0,0,250), thickness=2)\n",
    "    # Save the image\n",
    "    cv2.imwrite('face_eye_detection_result.png', img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0573e5f-e74d-40d9-bdae-4cd89961877a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "file = \"people1.jpg\"\n",
    "result = face_eyes_detection(image_path=file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "51d1a0d7-905b-4f2d-9ae1-2c0f4ba89967",
   "metadata": {},
   "outputs": [],
   "source": [
    "def car_detection(image_path):\n",
    "    # Read image\n",
    "    img = cv2.imread(image_path)\n",
    "    # Convert the image to grayscale\n",
    "    gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    # Create the car detector instance\n",
    "    car_detector = cv2.CascadeClassifier('cars.xml')\n",
    "    # Detect the cars\n",
    "    car_detections = car_detector.detectMultiScale(gray_img, scaleFactor=1.03, minSize=(10,10), minNeighbors=5, maxSize=(100,100))\n",
    "    # Create the bounding box on the original image\n",
    "    for (x_coor, y_coor, weight, height) in car_detections:\n",
    "        cv2.rectangle(img, (x_coor, y_coor), (x_coor+weight, y_coor+height), (0,245,250), thickness=2)\n",
    "    # Save the image\n",
    "    cv2.imwrite('car_detection_result.png', img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8badd1a3-1c7e-4ef7-b1c7-9e428844cb9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "file = \"car.jpg\"\n",
    "result = car_detection(image_path=file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cf9d1c4b-5494-4313-a830-2c2d6679a788",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clock_detection(image_path):\n",
    "    # Read image\n",
    "    img = cv2.imread(image_path)\n",
    "    # Convert the image to grayscale\n",
    "    gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    # Create the car detector instance\n",
    "    clock_detector = cv2.CascadeClassifier('clocks.xml')\n",
    "    # Detect the cars\n",
    "    clock_detections = clock_detector.detectMultiScale(gray_img, scaleFactor=1.03, minSize=(10,10), minNeighbors=1)\n",
    "    # Create the bounding box on the original image\n",
    "    for (x_coor, y_coor, weight, height) in clock_detections:\n",
    "        cv2.rectangle(img, (x_coor, y_coor), (x_coor+weight, y_coor+height), (0,255,230), thickness=2)\n",
    "    # Save the image\n",
    "    cv2.imwrite('clock_detection_result.png', img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "da78d8d9-5419-411a-8c01-2ea86b882514",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "file = \"clock.jpg\"\n",
    "result = clock_detection(image_path=file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1efa7ba8-c004-4de2-82c8-6b6cffebeee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_body_detection(image_path):\n",
    "    # Read image\n",
    "    img = cv2.imread(image_path)\n",
    "    # Convert the image to grayscale\n",
    "    gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    # Create the car detector instance\n",
    "    fullbody_detector = cv2.CascadeClassifier('fullbody.xml')\n",
    "    # Detect the cars\n",
    "    fullbody_detections = fullbody_detector.detectMultiScale(gray_img, scaleFactor=1.05, minSize=(50,50), minNeighbors=5)\n",
    "    # Create the bounding box on the original image\n",
    "    for (x_coor, y_coor, weight, height) in fullbody_detections:\n",
    "        cv2.rectangle(img, (x_coor, y_coor), (x_coor+weight, y_coor+height), (0,255,230), thickness=2)\n",
    "    # Save the image\n",
    "    cv2.imwrite('fullbody_detection_result.png', img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "22085109-dbd5-4578-ac36-0ac0ffcef754",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "file = \"people3.jpg\"\n",
    "result = full_body_detection(image_path=file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f6ddf3-c52f-4fd6-a4ac-9cc9003ca150",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
